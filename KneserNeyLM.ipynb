{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from collections import Counter, defaultdict\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    n_sen = 0\n",
    "    classes = []\n",
    "    for path, dirs, files in os.walk(path):   # each class\n",
    "        print(path)\n",
    "        data = []\n",
    "        for filename in files:      # each file\n",
    "            if filename[0] == '.':\n",
    "                continue\n",
    "            else:\n",
    "#                print(filename)\n",
    "                n_sen+=1\n",
    "                filePath = path + '/' + filename\n",
    "                text = open( filePath, 'r' ).read()       \n",
    "                data.append(parse_article(text))\n",
    "        classes.append(data)\n",
    "    return classes[1:]\n",
    "\n",
    "def parse_article(doc):\n",
    "#     TODO: tokenize sentence and transform to lower and padding\n",
    "    doc = doc.lower()\n",
    "    sens = sent_tokenize(doc)\n",
    "    sen_list = []\n",
    "    for sen in sens:\n",
    "        words = word_tokenize(sen)\n",
    "        sen_list.append(['<s>'] + words + ['<\\s>'])\n",
    "    return sen_list\n",
    "\n",
    "def to_bi(data):\n",
    "    bi_dict = defaultdict(int)\n",
    "    for i,word in enumerate(data[:-1]):\n",
    "        key = data[i]+' '+data[i+1]\n",
    "        bi_dict[key] += 1\n",
    "    return bi_dict\n",
    "\n",
    "def wi_1_type(bigram_count):\n",
    "    # for every wi, type(wi-1)\n",
    "    # ex. San Francisco, for \"Francisco\", type(\"XXX Francisco\")\n",
    "    type_count = defaultdict(lambda:0)\n",
    "    total_count = defaultdict(lambda:0)\n",
    "    for two_word in bigram_count.keys():\n",
    "        wi = two_word.split()[1]\n",
    "        type_count[wi] += 1\n",
    "        total_count[wi] += bigram_count[two_word]\n",
    "    return type_count, total_count\n",
    "\n",
    "cons = 1e-4\n",
    "def wi_type(bigram_count):\n",
    "    # for every wi-1, type(wi)\n",
    "    # ex. San Francisco, for \"San\", type(\"San XXX\")\n",
    "    type_count = defaultdict(lambda:cons)\n",
    "    total_count = defaultdict(lambda:cons)\n",
    "    for two_word in bigram_count.keys():\n",
    "        wi_1 = two_word.split()[0]\n",
    "        type_count[wi_1] += 1\n",
    "        total_count[wi_1] += bigram_count[two_word]\n",
    "    return type_count, total_count\n",
    "\n",
    "def count_prob(data):   \n",
    "    new_data = []\n",
    "    for doc in data:\n",
    "        for sen in doc:\n",
    "            new_data.extend(sen)\n",
    "    data = new_data\n",
    "    del new_data\n",
    "    \n",
    "    word_count = Counter(data)\n",
    "    bigram_count = to_bi(data)\n",
    "    bigram_len = len(bigram_count)\n",
    "    \n",
    "    wi_1_type_count, wi_1_total_count = wi_1_type(bigram_count)\n",
    "    wi_type_count, wi_total_count = wi_type(bigram_count)\n",
    "    \n",
    "    Pcontinue_dict = defaultdict(lambda:cons, zip(wi_1_type_count.keys(), [ max((wi_1_type_count[wi]-d)/bigram_len, cons) for wi in wi_1_type_count] ))    \n",
    "    return word_count, bigram_count, Pcontinue_dict, wi_type_count, wi_total_count\n",
    "\n",
    "def KNLM(two_word, model, d):\n",
    "    word_count, bigram_count, Pcontinue_dict, wi_type_count, wi_total_count = model\n",
    "    wi_1 = two_word.split()[0]\n",
    "    wi = two_word.split()[1]\n",
    "    bigram = max(bigram_count[two_word]-d, 0) / wi_total_count[wi_1]\n",
    "    pcontinue = Pcontinue_dict[wi]\n",
    "    lambda_ = wi_type_count[wi_1] * d / wi_total_count[wi_1]\n",
    "    prob = math.log(bigram + lambda_ * pcontinue,10)\n",
    "\n",
    "    return prob\n",
    "\n",
    "def score_article(doc, models, d):\n",
    "#     TODO: get label that has highest scores\n",
    "    doc_score = [0]*12\n",
    "    for i, model in enumerate(models):\n",
    "        for sen in doc:\n",
    "            doc_score[i] += score_sentence(sen, model, d)\n",
    "    prediction = np.argmax(doc_score)\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "def score_sentence(sen, model, d):    \n",
    "    bigram = [ sen[i]+' '+sen[i+1] for i,word in enumerate(sen[:-1]) ]\n",
    "    score = 0\n",
    "    \n",
    "    if len(sen) > 90:      \n",
    "        return 0   \n",
    "    else:\n",
    "        for bi in bigram:\n",
    "            score += KNLM(bi, model, d)\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load and preprocess training data\n",
      "reuters.tar/r_train\n",
      "reuters.tar/r_train\\acq\n",
      "reuters.tar/r_train\\corn\n",
      "reuters.tar/r_train\\crude\n",
      "reuters.tar/r_train\\earn\n",
      "reuters.tar/r_train\\grain\n",
      "reuters.tar/r_train\\interest\n",
      "reuters.tar/r_train\\money-fx\n",
      "reuters.tar/r_train\\oilseed\n",
      "reuters.tar/r_train\\ship\n",
      "reuters.tar/r_train\\soybean\n",
      "reuters.tar/r_train\\trade\n",
      "reuters.tar/r_train\\wheat\n",
      "load and preprocess testing data\n",
      "reuters.tar/r_test\n",
      "reuters.tar/r_test\\acq\n",
      "reuters.tar/r_test\\corn\n",
      "reuters.tar/r_test\\crude\n",
      "reuters.tar/r_test\\earn\n",
      "reuters.tar/r_test\\grain\n",
      "reuters.tar/r_test\\interest\n",
      "reuters.tar/r_test\\money-fx\n",
      "reuters.tar/r_test\\oilseed\n",
      "reuters.tar/r_test\\ship\n",
      "reuters.tar/r_test\\soybean\n",
      "reuters.tar/r_test\\trade\n",
      "reuters.tar/r_test\\wheat\n"
     ]
    }
   ],
   "source": [
    "\"\"\" main \"\"\"\n",
    "train_path = \"reuters.tar/r_train\"\n",
    "test_path = \"reuters.tar/r_test\"\n",
    "d = 0.75\n",
    "\n",
    "print(\"load and preprocess training data\")\n",
    "train_data = read_data(train_path) # class -> document -> sentence -> word\n",
    "print(\"load and preprocess testing data\")\n",
    "test_data = read_data(test_path) # class -> document -> sentence -> word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training\n",
      "model 0 OK\n",
      "model 1 OK\n",
      "model 2 OK\n",
      "model 3 OK\n",
      "model 4 OK\n",
      "model 5 OK\n",
      "model 6 OK\n",
      "model 7 OK\n",
      "model 8 OK\n",
      "model 9 OK\n",
      "model 10 OK\n",
      "model 11 OK\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "print('start training')\n",
    "for i, class_ in enumerate(train_data):\n",
    "    word_count, bigram_count, Pcontinue_dict, wi_type_count, wi_total_count = count_prob(class_)    \n",
    "#    pkn = KNLM(word_count, bigram_count, Pcontinue_dict, wi_type_count, wi_total_count, d) \n",
    "    models.append([word_count, bigram_count, Pcontinue_dict, wi_type_count, wi_total_count])\n",
    "    print(\"model\",i,\"OK\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start testing\n",
      "category_ 0 hit count: 89 / 100\n",
      "category_ 1 hit count: 6 / 33\n",
      "category_ 2 hit count: 71 / 96\n",
      "category_ 3 hit count: 77 / 95\n",
      "category_ 4 hit count: 27 / 59\n",
      "category_ 5 hit count: 19 / 50\n",
      "category_ 6 hit count: 52 / 63\n",
      "category_ 7 hit count: 6 / 28\n",
      "category_ 8 hit count: 26 / 49\n",
      "category_ 9 hit count: 0 / 22\n",
      "category_ 10 hit count: 44 / 55\n",
      "category_ 11 hit count: 7 / 33\n",
      "Accuracy:  0.6207906295754027\n"
     ]
    }
   ],
   "source": [
    "print(\"start testing\")\n",
    "test_data_len = sum(len(t) for t in test_data)\n",
    "total_hit = 0\n",
    "\n",
    "for i, class_ in enumerate(test_data):    \n",
    "    hit = 0\n",
    "    for doc in class_:\n",
    "        prediction = score_article(doc, models, d)\n",
    "        if prediction == i:\n",
    "            hit += 1\n",
    "            total_hit += 1\n",
    "    print(\"category_\", i, \"hit count:\", hit, \"/\", len(class_))\n",
    "print('Accuracy: ', total_hit/test_data_len)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
